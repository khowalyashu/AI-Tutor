Deakin University CRICOS Provider Code: 00113B
Presented by: 
Dr. Thommen George Karimpanal
School of Information Technology
SIT796 Reinforcement Learning
The Psychology behind Reinforcement Learning
Deakin University CRICOS Provider Code: 00113B
Like many areas of Artificial Intelligence, Reinforcement 
Learning builds on our studies in other fields.
‚Ä¢
Artificial Neural Networks based on Neurons.
‚Ä¢
Evolutionary algorithms based on biological evolution
‚Ä¢
Expert systems based on philosophical understanding of 
knowledge and logical inference
‚Ä¢
‚Ä¶
Reinforcement Learning is founded on Animal Behaviour 
(Psychology)
‚Ä¢
Classical Conditioning
‚Ä¢
Instrumental Conditioning and the Law of effect
‚Ä¢
Frequency of Reinforcement 
‚Ä¢
Delayed Reinforcement 
‚Ä¢
Habitual and Goal-directed behaviour
Motivation for Reinforcement Learning
2
Reinforcement 
Learning
Animal 
Psychology
Human 
Psychology
Deakin University CRICOS Provider Code: 00113B
Pavlovian (Classical)
‚Ä¢ Occurs because of the subject‚Äôs instinctive responses
‚Ä¢ A neutral stimulus gains the ability to elicit a response as 
a result of being paired with another stimulus
Operant (Instrumental)
‚Ä¢ Contingent on the willful actions of the subject
‚Ä¢ Occurs only after the organism executes a predesignated 
behavioral act.
Pavlovian vs Operant Conditioning
3
Deakin University CRICOS Provider Code: 00113B
Based on work originally done by Ivan Pavlov (1927).
An Unconditioned Response (UR) is an inborn response and 
occurs automatically based on an unconditioned stimuli (US). 
‚Ä¢
A dog automatically salivating when food is placed in front of 
it.
A Conditioned Response (CR) is learnt. Takes a previously  
neutral stimuli and turns it into a conditioned stimuli (CS)
‚Ä¢
Ringing a bell by itself is a neutral stimuli, producing no 
salivation in response.
‚Ä¢
Each time food is place in front of the dog a bell is rung
‚Ä¢
After a period of time ring the bell becomes a conditioned response and the dog will salivate when the bell is 
rung regardless of whether food is provided. 
The US is called a reinforcer because it reinforces the production of a CR when stimuli.
Classical Conditioning
4
https://edu.glogster.com/glog/ivan-pavlov/224aae54ua8?=glogpedia-source
In Instrumental Conditioning, or Operant conditioning as named by Skinner (1938),
a stimulus is delivered contingent on an animal‚Äôs behaviour. 
‚Ä¢
Whereas, a in Classical conditioning the US was provided regardless of behaviour.
Thorndike‚Äôs experiments (1898)
‚Ä¢
That a cat placed in a ‚Äòpuzzle box‚Äô may take around 300 seconds 
to accidently activate three switches that open the door and 
allow access to visible food. 
‚Ä¢
After successive experiences it got this down to 6 or 7 seconds
Lead him to the development of the Law of effect, describing 
the idea of trial-and-error. 
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning
5
Sutton and Barto 
https://www.researchgate.net/figure/One-of-the-puzzle-boxes-used-by-Thorndike-to-study-the-acquisition-of-new-behaviors-in_fig9_285777770
Deakin University CRICOS Provider Code: 00113B
Presented by: 
Dr. Thommen George Karimpanal
School of Information Technology
SIT796 Reinforcement Learning
Classical Conditioning
Deakin University CRICOS Provider Code: 00113B
Common types of classical conditioning experiments
Delayed Conditioning 
‚Ä¢
Applies the conditioned stimuli (CS) throughout the 
Interstimulus interval (ISI).
‚Ä¢
The unconditioned stimuli (US) is only applied at the end.
Trace Conditioning 
‚Ä¢
The US is only applied after the CS has completed. 
Results have illustrated that applying these approaches over a 
series of trials causes the animal to learn to predict the US
Hence, Predictive Reinforcement Learning is often regarded 
as an algorithmic form of Classical Conditioning. 
Classical Conditioning as Prediction
7
ISI
ùë°
CS
US
CS
US
Delay Conditioning
Trace Conditioning
Deakin University CRICOS Provider Code: 00113B
Higher-order conditioning
‚Ä¢
Higher order conditioning occurs when an animal is 
presented with a CS followed by a previously learn CS.
‚Ä¢
The animal learns to produce the same CR to the 
second CS.
‚Äì
This occurs even if the second CS was not followed by 
the original US.
‚Ä¢
This represents what is called second-order 
conditioning.
‚Ä¢
Can potentially be extended to higher orders
Classical Conditioning (Higher-order conditioning)
8
https://www.chegg.com/flashcards/pscyh-150-final-78c1de23-f8f6-41a1-88a7-dde0652b3b99/deck
Deakin University CRICOS Provider Code: 00113B
Stimulus Generalization
‚Ä¢
Animals can associate new stimuli, which are similar to already CS, to produce the same or similar CR
‚Ä¢
For instance, having survived a traumatic experience with a snake a cat will learn to avoid all snakes. 
Extinction
‚Ä¢
If a learnt CS is presented many times without the subsequent US resulting will eventually cause the animal to 
forget the conditioning.
‚Ä¢
For instance if I stop opening the door when the cat knocks it will eventually stop knocking.
Spontaneous recovery
‚Ä¢
After extinction, a CS can be recovered by reintroducing the CR.
‚Ä¢
Hence, if I go a week not opening the door to the cat but then forget and open the door it will recover the CS.
Conditioned Inhibition
‚Ä¢
The inverse can also be learnt ‚Äì where an animal learns that CS signals the absence of US. 
‚Ä¢
For example, my cat has learnt that if it hides in the linen press when there are young visitor at the house then it 
can avoid being harassed. 
Classical Conditioning (Other Findings)
9
Deakin University CRICOS Provider Code: 00113B
Presented by: 
Dr. Thommen George Karimpanal
School of Information Technology
SIT796 Reinforcement Learning
Operant Conditioning
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning (Law of Effect)
11
Law of effect
Behaviours followed by favourable consequences become 
more likely, and behaviours followed by unfavourable 
consequences become less likely. 
Found that learning goes beyond the process of simply finding behaviours that result in a high reward
Found it also includes the process of connecting those behaviours to the situations where those actions 
were taken
Called this learning by ‚Äúselecting and connecting‚Äù
Biological and computation models of evolution are based on ‚Äúselection‚Äù. 
‚Ä¢
There is no associative component
While supervised learning is only ‚Äúassociative‚Äù. Methods remember generalisation of associations  between 
inputs and outputs based on instruction.
‚Ä¢
There is no selection process
Reinforcement Learning is based on both the search and memory processes that are fundamental to both the 
Psychology and the computational models used to implement Reinforcement Learning agents.
‚Ä¢
IC‚Äôs focus on behaviours taken to reach a reward is often regarded as the basis of Reinforcement Learning for Control
Reinforcement Learning agents must:
‚Ä¢
Search for possible solutions through trial-and-error (eg applying the Law-of-effect)
‚Ä¢
Associate situations (states) to the outcomes observed. 
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning
12
Skinner (1938) introduced the new term into the Law of Effect - Reinforcement
‚Ä¢
Focusing on the idea of a reinforcement stimulus guiding behaviour.
Skinner developed a operant conditioning chamber ‚Äì now called a ‚ÄúSkinner Box‚Äù, found three responses
‚Ä¢
Positive Reinforcement 
‚Ä¢
Negative Reinforcement
‚Ä¢
Punishment
Found how these responses can be used to train animals. 
Ideas stemming from this idea
‚Ä¢
Human psychology in early and some later learning  
‚Ä¢
Learning and teaching theories
‚Ä¢
Changes in child rearing practices
‚Ä¢
And of course Reinforcement learning
‚Ä¢
‚Ä¶
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning
13
https://www.simplypsychology.org/operant-conditioning.html
Clark Hull (1943) found secondary reinforcement was possible. 
‚Ä¢
Like higher-order conditioning an animal can learn even when there is a significant time interval between action and 
the resulting reinforcement stimulus. 
The law of effect requires a backward effect on connections.
‚Ä¢
Relates to what Minsky (1961) referred to as the credit assignment problem
‚Äì
How do you distribute credit for success amongst many past decisions?
Trace conditioning
‚Ä¢
Pavlov (1927) suggested that a stimulus must leave a trace in the nervous system
‚Ä¢
Hull (1943) also suggested an animal had a goal gradient in instrumental conditioning
‚Ä¢
Suggested that this trace reduces exponentially over time
Reinforcement Learning utilises eligibility traces and a value function to enable learning with delayed reward
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning (Delayed Reinforcement)
14
Clark Hull (1943) found secondary reinforcement was possible. 
‚Ä¢
Like higher-order conditioning an animal can learn even when there is a significant time interval between action and 
the resulting reinforcement stimulus. 
The law of effect requires a backward effect on connections.
‚Ä¢
Relates to what Minsky (1961) referred to as the credit assignment problem
‚Äì
How do you distribute credit for success amongst many past decisions?
Trace conditioning
‚Ä¢
Pavlov (1927) suggested that a stimulus must leave a trace in the nervous system
‚Ä¢
Hull (1943) also suggested an animal had a goal gradient in instrumental conditioning
‚Ä¢
Suggested that this trace reduces exponentially over time
Reinforcement Learning utilises eligibility traces and a value function to enable learning with delayed reward
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning (Delayed Reinforcement)
15
Deakin University CRICOS Provider Code: 00113B
Instrumental Conditioning (Frequency of Reinforcement)
16
Fixed Ratio 
Reinforcement
Variable Ratio 
Reinforcement
Variable Interval 
Reinforcement
Continuous 
Reinforcement
Fixed Interval 
Reinforcement
Rate of Extinction
Rate of Response
FAST
SLOW
FAST
SLOW
Deakin University CRICOS Provider Code: 00113B
Presented by: 
Dr. Thommen George Karimpanal
School of Information Technology
SIT796 Reinforcement Learning
Cognitive Maps and Latent Learning
The concept was introduced by Edward 
Tolman (1948)
‚Ä¢
These are mental representations that increase 
recall and learning of information
‚Ä¢
They are presumed to be learned by gradually 
acquiring elements of the world
‚Ä¢
As cognitive, they are often presumed to differ 
from "true" maps of the environment.
‚Ä¢
Cognitive maps are not restricted to spatial 
layouts, but can apply more generally to model an 
animals task space (Wilson, Takahashi, Schoenbaum, and Niv, 2014)
Deakin University CRICOS Provider Code: 00113B
Cognitive Maps as Environmental 
Representations
18
Latent Learning considers whether an animal learns a cognitive 
map of an environment even if there is no reason to do so.
Edward Tolman (1948) used a maze to show that this learning with 
3 groups of rats
‚Ä¢
Group 1 group always has food at the end
‚Ä¢
Group 2 has no food at the end until trial 12 when food is now 
placed at the end
‚Ä¢
Group 3 never has food at the end.
While Instrumental Conditioning is the basis of Value-based 
Reinforcement Learning, Cognitive maps are analogous to Model-based 
Reinforcement Learning
Deakin University CRICOS Provider Code: 00113B
Latent Learning of Cognitive Maps
19
https://courses.lumenlearning.com/wmopen-psychology/chapter/psychology-in-real-life-latent-learning/
Instrumental Conditioning (Value-based RL) corresponds to Habitual behaviour. 
‚Ä¢
Habitual behaviour is fast, automatic and reactionary
‚Ä¢
In RL Value-Based approaches are also referred to as Model-Free
Cognitive maps (model-based RL) is considered to be a Goal-directed control.  
‚Ä¢
Goal-directed behaviour is purposeful/intentional and uses knowledge of the environments
Deakin University CRICOS Provider Code: 00113B
Habitual and Goal-directed Behaviour
20
4
0
2
3
S1
S2
S3
State/Action
Q-Value
S1/Left
4
S1/Right
3
S2/Left
0
S2/Right
4
S3/Left
2
S3/Right
3
S1
S2
S3
0
4
2
3
Problem
Model-Free
Model-Based
Deakin University CRICOS Provider Code: 00113B
This was a quick overview of Psychology 101.
‚Ä¢
Intention was to link the ideas and terminology in Psychology to 
those used in Reinforcement Learning
‚Ä¢
Inspire an intuitive understanding of RL in real world terms.
For more detailed information see Sutton and Barto (2018) 
Reinforcement Learning: An Introduction
‚Ä¢
Chapter 14
‚Ä¢
http://incompleteideas.net/book/RLbook2020.pdf
Conclusion
21
